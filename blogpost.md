We love [Slack](https://slack.com/), a messaging app popular among developers, that brings communication together in one place. It provides real-time messaging as well as archiving and searching for teams while organizing conversations into channels. More often than not, however, the name of a channel is not informative enough to understand which topics are relevant to the channel. While veterans just *know* where to post content, new members of the team may struggle and ultimately post messages in the wrong channels. Nobody wants to be that nagging veteran team member trying to direct the rookie to a more appropriate place — let a bot do the work! I built a bot that learns the topics of different Slack channels, monitors conversations, and warns users when they go off topic. Give it a try [here](https://slack-police.slack.com) or have a look at the illustration of its functionality below:
<p><img src="images/usage_animation.gif" width="700px" hspace="20" vspace="20" align="center"></p>



# Bot Brains: Word Mover's Distance With a Twist

At its heart, the bot needs to be able to compare two messages (documents): the user's input and messages already present in a channel. A standard way to compare two documents is to use [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) (BoW), which includes approaches such as [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) and cosine similarity. However, BoW does not capture semantic properties of words, and problems arise when documents share related but not identical words (e.g. "press" and "media").

To address this, I used [Word Mover's Distance](http://jmlr.org/proceedings/papers/v37/kusnerb15.pdf), a novel similarity metric built on top of (and leveraging) [word embeddings](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf). Word embeddings are high dimensional representations of words that capture their semantic properties (i.e. distributional semantics). Essentially words of similar meaning "live" close to one another in this high dimensional space. I used pre-trained word embeddings from [Spacy](https://spacy.io/) trained on the Common Crawl corpus.

With the idea of word embeddings, a natural way to estimate how dissimilar (or *distant*) two documents are is to look at the distance between the corresponding word vectors and, roughly speaking, add up those distances. That is the main idea behind the Word Mover's Distance approach, and neatly, it is an instance of the well-known [Earth Mover's Distance](https://en.wikipedia.org/wiki/Earth_mover's_distance) (EMD) optimization problem, only formulated in the word embedding space. 

### WMD = Earth Mover's Distance for Document Similarity

The EMD assumes that one has two collections of vectors, let's call them the *senders* and the *receivers*, and a matrix of their pair-wise distances. Additionally, each of the vectors has a weight, a real number smaller than 1, indicating how much "goods" each of the sender vectors has to send and how much of the goods each of the receiver vectors needs to receive. The sum of all the weights for the receiver vectors is normalized to 1, as it is for the sender vectors. 

The EMD can now be posed as a transportation problem: given the distances (costs) between the sender-receiver pairs, determine the most efficient way to *move* the goods from the senders to the receivers, allowing for partial sending and receiving (i.e. so that a sender can send a portion of its goods to one receiver and another portion to another receiver). This problem is obviously a non-trivial constrained optimization problem, and it has a known solution, which can be easily implemented in Python with the [`pyemd`](https://pypi.python.org/pypi/pyemd) package.

WMD is the application of the EMD problem to the context of word embeddings where the senders and receivers are word embeddings of words from the first and second document we're comparing, respectively. The weights of the vectors are chosen to be proportional to the number of times the corresponding word appears in the document, and the distances between the vectors are calculated using standard Euclidean distances in the word embedding space. In this way we can easily calculate the WMD distance between two documents using the `pyemd` package.

### *O(p^3 log(p))*, Terrible Time Complexity

A practical obstacle in applying this method to our case is the fact that the EMD algorithm has a terrible time complexity: *O(p^3 log(p))*, where *p* is the number of unique words in the two documents. We would need to compare the user's input to all of the previous messages in all the channels, calculate the average distance for each of the channels, and identify the one with the smallest average distance as our prediction for the channel the user's message belongs to. If the user posted the message in the channel we predicted the bot doesn't do anything; otherwise the bot will advise the user to consider posting it to the predicted channel. For Slack teams that contain a lot of messages spread out over numerous channels, this approach will not be feasible for a real-time response. 

So, let's modify WMD. Comparing the input message to *all* the messages in a given channel seems excessive. Surely there are messages that are more "representative" of the channel content than the others, and it's likely sufficient to compare the user input to those messages only. However, this approach would require expensive preprocessing, in which we essentially have to sort the channel messages using WMD as a key. Can we somehow construct a single message representative of an entire channel? 

### Slack Channel "Fingerprints"
Intuitively, this representation could be achieved by looking at the word distributions in a given channel. To a human, looking at the first 10 or so of the most frequently occuring words in a channel would give a pretty good idea of what that channel is about. A single message representative of that channel should therefore contain only those 10 (or so) words! This is where word embeddings are crucial: even if the user's input belongs to a channel but does not contain any of the words from its representative message, WMD distance will still be rather short, due to the semantic similarity between the user's word vectors and the word vectors in the representative message. 

To use the representative message in EMD / WMD, we need to choose the weights of the vectors representing the words in it. Since the weights in a standard WMD are directly proportional to how many times a given word appears in a message, we can make the weights in our representative message proportional to the number of times a given word appears in the entire channel (and then normalize it). Once we construct representative messages for each of the channels, all we need to do is calculate the WMD distances between the user's input message and each of the representative messages, find the shortest one, and predict the corresponding channel as the one the input message is supposed to go to. 

But are the top 10 words enough to form a representative message? How about 30? We can find the optimal number of top words by treating it as a hyperparameter and tuning it on a validation set.



# Implementing the Bot

Now that we have the bot's brains all figured out, in order to actually build and train the bot, we need some data. 

### Data: Reddit in Place of Slack
Slack data is hard to come by since it's private. The next best thing is [Reddit](https://www.reddit.com/) given that its data is easily available and has a similar structure to Slack, where instead of channels, different topics are grouped into subreddits. To build the bot prototype, I chose the following five topics (subreddits): *Diving*, *Handball*, *Corgi*, *Data Science*, and *Machine Learning*. These have been chosen intentionally so that some of the topics are more similar to each other and others are less so (plus, they also tell you something about the things I like!). The relevant data (submissions and comments) can then be downloaded using Reddit's excellent API through an easy-to-use [`PRAW`](https://praw.readthedocs.io/en/latest/#) package for Python, and stored in a SQL database. 

To showcase the bot's abilities, I made a [demo Slack team](https://slack-police.slack.com) where I created 5 channels, corresponding to the 5 subreddits above, and populated those channels with the comments obtained from the corresponding subreddits. For simplicity, I focused only on comments rather than the submissions since they tend to be shorter, perhaps more faithfully mimicking the form of Slack messages. To upload the Reddit data to my Slack team, I registered 4 [bot users](https://api.slack.com/bot-users) on Slack (posing as famous characters on Seinfeld!), and used the excellent package [`slackclient`](https://github.com/slackapi/python-slackclient) that allows one to communicate with Slack's API from Python. For more details on how to build simple bots in Python, check out my code on Github and / or have a look at a great tutorial from the [Full Stack Python](https://www.fullstackpython.com/blog/build-first-slack-bot-python.html) blog. The bot itself is hosted on [AWS](https://aws.amazon.com/), constantly monitoring the discussions in the demo Slack team.

### Initial Model Performance
We can now apply the bot's brains to this Reddit data. The first step is to tune the optimal number of *top words* in the channels' representative messages, which turns out to be 180. Below we see the confusion matrix for the test set, showing the distributions of messages from their true categories over the predicted ones. The accuracy of this model is about 74%, which is pretty good and a noticeable improvement from 68% that one gets from the tf-idf approach and using the cosine similarity as the metric. 
<img align="center" width="300px" src="images/confusion_matrix.png" hspace="20" vspace="20" />

### Turns Out "Thank You's" Can Be Annoying 
In the confusion matrix we see some expected confusion with the closely related topics: for example, 24% of messages from the machine learning channel got misclasified as data science. If we look under the hood, we can see that a lot of these messages are in fact pretty generic (e.g. "thank you") and could belong to any channel. In fact, our model picked up on the fact that the distances to all the channels for these messages are pretty similar, and it just happens that the distance to the data science channel was the shortest one. 

To eliminate some of these "generic" messages, let's introduce a threshold: when the distance between the channel the message was posted in and the channel that the message was classified into belong to is smaller than some value *epsilon*, we'll ignore the prediction of the model and the bot won't alert the user. To keep things simple we will use a fixed, relative threshold for the entire corpus, treat it as a hyperparameter, and tune it on the validation set.

However, as the messages are not labeled as generic or non-generic we cannot code up some automatic verification process that tells us how accurately the model is performing in flagging messages as generic (for a given value of the threshold). We would need an actual human being to look at the example the model flagged as generic and decide if it is indeed generic. That seems cumbersome! Is there a more practical approach?

### Maximizing the High Accuracy Likelihood
In order not to decrease the accuracy of our model too much, we would like to minimize the number of correctly classified messages that are flagged as generic. Because flagging a message as generic introduces a possibility that we mis-flagged it, this would decrease the accuracy of the model. On the other hand, in order to try to increase the accuracy of our model, we would like to maximize the number of incorrectly classified messages flagged as generic. Given that flagging a message as generic introduces a possibility that we correctly flagged it, this would increase the accuracy of the model. As we increase the threshold, the amount of correctly classified messages predicted to be generic will increase, while the amount of the incorrectly classified messages predicted to be non-generic will decrease, as shown in the plot below. 
<img width="300px" src="images/threshold.png" hspace="20" vspace="20" />

A natural choice for the optimal relative threshold is the place where the two curves intersect, which is about 0.05 in our case. Now that we have chosen an optimal threshold, we apply our model to the test set, manually check how many of the messages our model flagged as generic are indeed generic, and use that to update the effective accuracy of the model. **This results in the final accuracy of about 84%**, a substantial improvement from the initial 74%.



# Final Words

In summary, I've built a reasonably smart bot for Slack that helps users stay on topic. It does so by using some of the most recent methods for natural language processing, word embeddings and Word Mover’s Distance. In order to ensure a real-time response of the bot, I needed to modify the WMD approach by constructing a single representative message for each Slack channel, which allowed for a fast comparison between the user's input and channels' content. Finally, in order to achieve the high accuracy of 84%, I needed to tackle the “generic” messages (i.e. messages that could belong to any of the channels) by introducing a relative threshold and a practical way to tune it so that the likelihood of high accuracy is maximized.

This bot prototype is pretty versatile: it can be applied to platforms other than Slack (such as Reddit and Stack Overflow), and it can be also potentially developed into more advanced applications, including automatic email classification and perhaps even filtering out hate speech on Twitter.

This is a project I built in three weeks at [Insight](http://insightdatascience.com/). That's not a lot of time, but it's been a lot of fun! I have a lot of ideas as to how to take this whole project further including improving the user experience with buttons and slash commands, better estimating the bot’s performance in the real world, dealing with the problem of cold start, and many more. Check out my original [blog post on Github](https://aficnar.github.io/slackpolice/) for more details, as well as the [bot's code](https://github.com/aficnar/slack_police).
