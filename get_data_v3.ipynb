{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**1. Connect to Reddit and choose subreddits to download**](#reddit_connect)\n",
    "\n",
    "[**2. Build the SQL database**](#build_sql)\n",
    "\n",
    "[**3. Pull all the subreddit data and save it to SQL DB**](#pull_reddit)\n",
    "\n",
    "[**4. Populate Slack channels with Reddit data**](#populate_slack)\n",
    "\n",
    "[**5. Commit & close connection**](#close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import praw, psycopg2, sys, time, subprocess, random, os\n",
    "import pandas as pd\n",
    "from slackclient import SlackClient\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT # Trick to be able to create a DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"reddit_connect\">1. Connect to Reddit and choose subreddits to download</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open my Postgres app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subprocess.call([\"/usr/bin/open\", \"-n\", \"-a\", \"/Applications/Postgres.app\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Reddit API via `PRAW`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = os.environ[\"PRAW_CLIENT_ID\"],\n",
    "                     client_secret = os.environ[\"PRAW_CLIENT_SECRET\"],\n",
    "                     password = os.environ[\"PRAW_PASSWORD\"],\n",
    "                     user_agent = 'slackbot by /u/aficnar',\n",
    "                     username = 'aficnar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose subreddits to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning\n"
     ]
    }
   ],
   "source": [
    "subreddit_try = 'MachineLearning'\n",
    "subreddit = reddit.subreddit(subreddit_try)\n",
    "print(subreddit.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_subreddits = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"build_sql\">2. Build the SQL database</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a local SQL database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# con = psycopg2.connect(database = 'postgres', user = 'aficnar')\n",
    "# con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "# cur = con.cursor()\n",
    "# cur.execute(\"CREATE DATABASE slack_police\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the DB and, if necessary, drop the previous tables (from failed attempts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = psycopg2.connect(database = 'slack_police', user = 'aficnar')\n",
    "cur = con.cursor()\n",
    "#cur.execute(\"DROP TABLE main_subreddits\")\n",
    "#cur.execute(\"DROP TABLE main_submissions\")\n",
    "#cur.execute(\"DROP TABLE main_comments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a table that will store the subreddit names, id's, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cur.execute(\"\"\"\n",
    "#            CREATE TABLE main_subreddits\n",
    "#            (\n",
    "#            id VARCHAR(255) NOT NULL,\n",
    "#            name TEXT NOT NULL,\n",
    "#            title TEXT NOT NULL, \n",
    "#            created INT NOT NULL,\n",
    "#            total_submissions INT NOT NULL\n",
    "#            )\n",
    "#            \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the chosen subreddits in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(chosen_subreddits)):\n",
    "    subreddit = reddit.subreddit(chosen_subreddits[i])\n",
    "    db_tuple = (subreddit.id, chosen_subreddits[i], subreddit.title, \n",
    "                int(subreddit.created), 0)\n",
    "    cur.execute(\"INSERT INTO main_subreddits VALUES (%s, %s, %s, %s, %s)\", db_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>created</th>\n",
       "      <th>total_submissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2qr9w</td>\n",
       "      <td>diving</td>\n",
       "      <td>Scuba Diving and Snorkeling</td>\n",
       "      <td>1231768360</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2rr72</td>\n",
       "      <td>Handball</td>\n",
       "      <td>Handball</td>\n",
       "      <td>1273801402</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2rdw8</td>\n",
       "      <td>corgi</td>\n",
       "      <td>Corgi Subreddit</td>\n",
       "      <td>1260187617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2sptq</td>\n",
       "      <td>datascience</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1312659822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2r3gv</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>1248906884</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             name                        title     created  \\\n",
       "0  2qr9w           diving  Scuba Diving and Snorkeling  1231768360   \n",
       "1  2rr72         Handball                     Handball  1273801402   \n",
       "2  2rdw8            corgi              Corgi Subreddit  1260187617   \n",
       "3  2sptq      datascience                 Data Science  1312659822   \n",
       "4  2r3gv  MachineLearning             Machine Learning  1248906884   \n",
       "\n",
       "   total_submissions  \n",
       "0               1149  \n",
       "1                793  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"SELECT * FROM main_subreddits\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tables that will contain the submissions and comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cur.execute(\"\"\"\n",
    "#            CREATE TABLE main_submissions\n",
    "#            (\n",
    "#            id VARCHAR(255) NOT NULL,\n",
    "#            subreddit_id VARCHAR(255) NOT NULL,\n",
    "#            content TEXT\n",
    "#            )\n",
    "#            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cur.execute(\"\"\"\n",
    "#            CREATE TABLE main_comments\n",
    "#            (\n",
    "#            id VARCHAR(255) NOT NULL,\n",
    "#            subreddit_id VARCHAR(255) NOT NULL,\n",
    "#            submission_id VARCHAR(255) NOT NULL,\n",
    "#            content TEXT\n",
    "#            )\n",
    "#            \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the relevant tables and columns in our DB and display them nicely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "            SELECT table_name \n",
    "            FROM information_schema.tables\n",
    "            WHERE table_name LIKE 'main_%'\n",
    "            \"\"\"\n",
    "table_list = pd.read_sql(sql_query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "            SELECT column_name, table_name \n",
    "            FROM information_schema.columns\n",
    "            WHERE table_name LIKE 'main_%'\n",
    "            \"\"\"\n",
    "col_list = pd.read_sql(sql_query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_comments</th>\n",
       "      <th>main_submissions</th>\n",
       "      <th>main_subreddits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>id</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subreddit_id</td>\n",
       "      <td>subreddit_id</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submission_id</td>\n",
       "      <td>content</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>content</td>\n",
       "      <td>-----</td>\n",
       "      <td>created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-----</td>\n",
       "      <td>-----</td>\n",
       "      <td>total_submissions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   main_comments main_submissions    main_subreddits\n",
       "0             id               id                 id\n",
       "1   subreddit_id     subreddit_id               name\n",
       "2  submission_id          content              title\n",
       "3        content            -----            created\n",
       "4          -----            -----  total_submissions"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a dictionary containing all column names\n",
    "DF_dict = {}\n",
    "for name in list(table_list['table_name']):\n",
    "    DF_dict[name] = list(col_list[col_list['table_name'] == name]['column_name'])\n",
    "\n",
    "# Fill it up so all lists are equal length\n",
    "max_length = max([len(f) for f in DF_dict.values()])\n",
    "for key, value in DF_dict.items():\n",
    "    DF_dict[key] = DF_dict[key] + ['-----'] * (max_length - len(DF_dict[key]))\n",
    "\n",
    "# Create a DataFrame\n",
    "all_columns = pd.DataFrame(DF_dict)\n",
    "all_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"pull_reddit\">3. Pull all the subreddit data and save it to SQL DB</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, couple of functions that we'll use to display the remaining time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stringify(num):\n",
    "    num_string = str(num)\n",
    "    if len(num_string) == 1: num_string = '0' + num_string\n",
    "    return num_string\n",
    "\n",
    "def convert_secs(secs_float):\n",
    "    secs = int(round(secs_float))\n",
    "    sec_display = secs % 60\n",
    "    mins = secs // 60\n",
    "    mins_display = mins % 60\n",
    "    hrs_display = mins // 60\n",
    "    export_string = stringify(hrs_display) + ':' + stringify(mins_display) + ':' + stringify(sec_display)\n",
    "    return export_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the subreddits to be downloaded in `pull_df` (useful for adding other subreddits later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>created</th>\n",
       "      <th>total_submissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2rdw8</td>\n",
       "      <td>corgi</td>\n",
       "      <td>Corgi Subreddit</td>\n",
       "      <td>1260187617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2sptq</td>\n",
       "      <td>datascience</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>1312659822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2r3gv</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>1248906884</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             name             title     created  total_submissions\n",
       "0  2rdw8            corgi   Corgi Subreddit  1260187617                  0\n",
       "1  2sptq      datascience      Data Science  1312659822                  0\n",
       "2  2r3gv  MachineLearning  Machine Learning  1248906884                  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_sql(\"SELECT * FROM main_subreddits\", con)\n",
    "pull_df = all_df.iloc[2:]\n",
    "pull_df.index = range(pull_df.shape[0])\n",
    "pull_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the above subreddits, submissions and comments and save them to DB -- and if you've crossed the `comments_threshold`, stop early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_threshold = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit 1 / 3: Corgi Subreddit\n",
      "Comments processed: 5006 / \n",
      "Runtime: 00:20:53\n",
      "--------------------------------------------------\n",
      "Subreddit 2 / 3: Data Science\n",
      "Comments processed: 5008 / \n",
      "Runtime: 00:16:18\n",
      "--------------------------------------------------\n",
      "Subreddit 3 / 3: Machine Learning\n",
      "Comments processed: 5013 / \n",
      "Runtime: 00:07:51\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(pull_df.shape[0]):\n",
    "    t_start = time.time()\n",
    "    print \"Subreddit \" + str(i + 1) + \" / \" + str(pull_df.shape[0]) + \": \" + pull_df['title'][i]\n",
    "    # Get relevant subreddit info\n",
    "    subreddit = reddit.subreddit(pull_df['name'][i])\n",
    "    subreddit_id = pull_df['id'][i]\n",
    "    comment_count = 0\n",
    "    # Loop over all the submissions\n",
    "    for submission in subreddit.submissions():\n",
    "        submission.comments.replace_more(limit = 0); # Important for deep comments\n",
    "        submission_tuple = (submission.id, subreddit_id, submission.selftext)\n",
    "        comment_tuples = []\n",
    "        # Loop over all the comments in this submission\n",
    "        comment_list = submission.comments.list()\n",
    "        for comment in comment_list:\n",
    "            comment_tuples.append((comment.id , subreddit_id, submission.id, comment.body))\n",
    "        if len(comment_tuples) > 0:\n",
    "            comment_str = ','.join(cur.mogrify(\"(%s,%s,%s,%s)\", x) for x in comment_tuples)\n",
    "            cur.execute(\"INSERT INTO main_comments VALUES \" + comment_str) \n",
    "        cur.execute(\"INSERT INTO main_submissions VALUES (%s, %s, %s)\", submission_tuple)\n",
    "        comment_count = comment_count + len(comment_list)\n",
    "        # The rest is for pretty tracking of progress\n",
    "        sys.stdout.write(\"\\rComments processed: %d\" % comment_count)\n",
    "        sys.stdout.flush()\n",
    "        # Exit if you've downloaded more than comments_threshold comments\n",
    "        if comment_count > comments_threshold: break\n",
    "    t_finish = time.time()\n",
    "    print\n",
    "    print 'Runtime: ' + convert_secs(t_finish - t_start)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the total amount of submissions and comments downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26023\n",
      "4770\n"
     ]
    }
   ],
   "source": [
    "all_comments = pd.read_sql(\"SELECT * FROM main_comments\", con)\n",
    "all_submissions = pd.read_sql(\"SELECT * FROM main_submissions\", con)\n",
    "print all_comments.shape[0]\n",
    "print all_submissions.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"populate_slack\">4. Populate Slack channels with Reddit data<a/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a Slack team called `Slack Police`, and I created 5 bots there. \n",
    "* The idea is to pick one of the first four bots here randomly as we upload the messages to Slack, so it looks like a real conversation. \n",
    "* The last bot, `officer_newman` will be the one monitoring discussions and warning about users going off-topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bot_tokens = [os.environ[\"SLACKBOT_TOKEN_JERRY\"],\n",
    "              os.environ[\"SLACKBOT_TOKEN_ELAINE\"],\n",
    "              os.environ[\"SLACKBOT_TOKEN_COSMO\"],\n",
    "              os.environ[\"SLACKBOT_TOKEN_GEORGE\"],\n",
    "              os.environ[\"SLACKBOT_TOKEN_NEWMAN\"]]\n",
    "bot_names = ['jerry', 'elaine', 'cosmo', 'george', 'officer_newman']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Slack clients via `slackclient` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slack_uploaders = [SlackClient(bot_tokens[i]) for i in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the uploaders see the channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'C3WJDNPCJ', u'ex1_diving'),\n",
       " (u'C3WJDPEHG', u'ex2_handball'),\n",
       " (u'C3WV35AEN', u'ex3_corgi'),\n",
       " (u'C3W93G2F3', u'ex4_data_science'),\n",
       " (u'C3XKZSM1V', u'ex5_machine_learning'),\n",
       " (u'C3UTPTUMT', u'general'),\n",
       " (u'C3UTDRVT6', u'random')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_list = slack_uploaders[0].api_call(\"channels.list\")['channels']\n",
    "[(c['id'], c['name']) for c in channel_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the subreddits to be uploaded and the corresponding channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diving', 'Handball', 'corgi', 'datascience', 'MachineLearning']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subreddit_upload_names = pd.read_sql(\"SELECT name FROM main_subreddits\", con)['name'].tolist()\n",
    "all_subreddit_upload_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'C3WJDNPCJ', u'C3WJDPEHG', u'C3WV35AEN', u'C3W93G2F3', u'C3XKZSM1V']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_channel_upload_list = [channel_list[i]['id'] for i in range(len(all_subreddit_upload_names))]\n",
    "all_channel_upload_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corgi', 'datascience', 'MachineLearning']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_upload_names = all_subreddit_upload_names[2:]\n",
    "channel_upload_list = all_channel_upload_list[2:]\n",
    "subreddit_upload_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over them and, for now, just upload the first `comment_limit` comments, also pausing for 1s, due to Slack's API rate limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comment_limit = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i_sub in range(len(subreddit_upload_names)):\n",
    "    # Get the comments from a given subreddit\n",
    "    sql_query = \"\"\"\n",
    "                SELECT content \n",
    "                FROM main_comments \n",
    "                WHERE subreddit_id = (\n",
    "                    SELECT id \n",
    "                    FROM main_subreddits \n",
    "                    WHERE name = '%s'\n",
    "                    )\n",
    "                \"\"\" % subreddit_upload_names[i_sub]\n",
    "    comments = pd.read_sql(sql_query, con)['content'].tolist()[:comment_limit]\n",
    "    # Upload each comment to Slack as a random bot\n",
    "    for c in comments:\n",
    "        bot_index = random.randint(0,3)\n",
    "        slack_uploaders[bot_index].api_call(\"chat.postMessage\", channel = channel_upload_list[i_sub],\n",
    "                                            text = c, as_user = True);\n",
    "        time.sleep(1)\n",
    "        cnt = cnt + 1\n",
    "        output_string = \"\\rTime remaining: \" + convert_secs(comment_limit * len(subreddit_upload_names) - cnt)\n",
    "        sys.stdout.write(output_string)\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"close\">5. Commit & close connection</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con.commit()\n",
    "cur.close()\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:my_projects_env]",
   "language": "python",
   "name": "conda-env-my_projects_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
